{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBtk_tC8zmC1"
      },
      "source": [
        "## PDF Query Using Langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v8fCmC-6Q3pP"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = ''\n",
        "api_key = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "_aQ7ps_dRJOq"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
        "# # os.environ[\"SERPAPI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_FA1ZERdRLAM"
      },
      "outputs": [],
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader(r'C:\\Users\\Mourya\\Desktop\\Resumes\\CKMourya_Resume.pdf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "q9AeO9cDRqMj"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "yGlxUMl-Rsmy",
        "outputId": "e248b48b-ffc3-457e-b1ba-406a41e1f86b"
      },
      "outputs": [],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VP6ap_PSRt7s"
      },
      "outputs": [],
      "source": [
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wqy4vJhrSXUT"
      },
      "outputs": [],
      "source": [
        "# Download embeddings from OpenAI\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3igYiWjISjvS"
      },
      "outputs": [],
      "source": [
        "document_search = FAISS.from_texts(texts, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Po-ip1fPSonv"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "iYl2PzKSSqg0"
      },
      "outputs": [],
      "source": [
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "GQafhpOz4IsV",
        "outputId": "b05ede70-3d69-40ee-a4af-ba0bd14659b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' Chinta Krishna Mourya has experience in data science internship at iNeuron.ai, where he developed an end-to-end credit card default prediction model using Python and ML tools, conducted EDA, data preprocessing and model selection, designed project architecture and built a Flask webapp, and gained experience in various ML techniques, Python programming, and deployment.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"experience of mourya\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
